---
categories: note
layout: post
---

- Table
{:toc}
# 第一章 介绍

## 1.1 例子：多项式曲线拟合

假设我们在$t=\sin(2\pi x)$的曲线上采样若干个点$(x_1, t_1), (x_2, t_2), \ldots ,(x_N, t_N)$作为训练集合，并向目标值加入一些满足高斯分布的噪音。现在我们希望通过多项式对原来的曲线进行拟合。
$$
y = w_0 + w_1x^1 + \ldots + w_Mx^M
$$


上面的M是多项式的阶数。我们的目标是得到系数$ w$的值。我们通过将多项式适配到训练数据来得到系数。这个过程可以通过最小化误差函数实现，误差函数用于测量函数$y( x,  w)$与正确标签之间的不匹配度。一个简单的误差函数的选择是计算每个点上，预测值与正确值的差的平方和，即：

$$
E(w)=\frac{1}{2} \sum_{i=1}^N{(y(x_i, w)-t_i)^2}
$$


我们的目标就是使上面公式值最小化，0是理想误差值，这意味在在训练数据上我们的函数$y$与$t$拥有相同的值。

由于误差函数$E$是$w$的二阶多项式，因此误差函数的导数是一阶多项式，这意味着误差函数的导数只有唯一的一个零点$w^\*$，而$E(w^\*)$一定是$E$所能取到的最小值，而结果多项式$y(x,w^\*)$就是我们要求的函数。

但是$M$值应该选择多少呢，过小的$M$值不够灵活，很可能无法达到足够的拟合。而过大的$M$会完全拟合训练集中的数据，但是最终得到的多项式系数过大，在对于测试集中的数据进行测试时偏差非常大，这种情况称为过拟合。

我们的目标是能得到能很好预测新输入的函数。对于选择的每一个$M$，得到其最优的$w^\*$后，我们可以将误差函数作用在测试集合上来观察$y(x,w^\*)$的实际效果。由于平方和与样本数量想关，因此更方便的方式是使用均方根来作为损失函数。

$$
E_{RMS}=\sqrt[2]{\frac{2E(w)}{N}}
$$


这样训练集上的均方根可以用于衡量$y(x,w)$对新数据的预测能力。

实际上，随着我们增大$M$，训练数据上的均方根会不断减少直到$0$为止，而在训练数据上的均方根会先减少后快速上升。由于阶数较大的多项式能完全包含阶数较小的多项式，因此随着阶数的上升，在训练集合上的均方根会不断减少（由牛顿插值公式可知可以得到经过所有点的多项式，因此均方根最后会降低为$0$）。

之所以过大的$M$会导致测试集合上均方根过大，是由于$y(x,w)$的部分系数过大。但是随着训练集合的增大，过拟合问题将变得不那么严重。即，越大的训练集合，越能负担更复杂的模型。粗略推荐使用模型参数的数量的倍数大小（5或10）的训练集合。但是训练集合的大小并一定是模型复杂度最好的衡量方式。

并且按照可用训练集的大小来限定模型参数的数目并不让人满意。看起来按照要解决的问题的复杂度来选择模型的复杂度是更加可信的方式，

我们将看到最小平方的方式寻找参数模型，实际是最大似然估计的一种特殊情况，而过拟合问题则可以被理解为最大似然估计的一个通常属性。通过采用贝叶斯方法，可以避免过拟合问题。我们将看到可以通过贝叶斯视角毫无难度地采用一个参数数目远超训练集大小的模型。实际上，在贝叶斯模型中，有效 参数数目会自动适应训练集的大小。

目前，用现在的方法继续并思考如何在实践中在较小的训练集合上采用更加灵活复杂的模型，是非常有益处的。正则化是一种经常用来在这种情况下控制过拟合现象的技术。它通过向误差函数追加一项惩罚项，来阻碍模型的参数值过大。最简单的惩罚项，是取所有参数的平方和。这样导出新的误差函数：

$$
\stackrel{\sim}{E}=\frac{1}{2}\sum_{n=1}^N{\{y(x_n,w)-t_n\}^2}+\frac{\lambda}{2}||w||^2
$$
其中$||w||^2=ww^T=w_0^2+w_1^2+\ldots+w_M^2$，系数$\lambda$用于调整正则项对结果影响的强度。一般$w_0$不会算在正则化子中，因为如果加入$w_0$，会导致误差依赖于选择的模型在$x=0$时所取的值，或则可以加入$w_0$，但是要分配一个独立的系数。在统计学中，这样的技术称为收缩方法，因为他们会减少系数的值。上面的二阶正则化子的特殊情况称为脊回归（ridge regression）。在神经网络上下文中，这种方法也称为权重衰退（weight decay）。

过小的调整因子会导致最终模型系数过大，而过大的调整因子会使得最终的模型趋向于直线，缺乏预测能力。只有合适的调整因子才可以真正得到合适的模型。

可以将训练集合切分为两部分，第一部分为训练集合，第二部分为验证集合。前者用于得到最优的系数$w^\*$，而后者则用于优化模型的复杂度（比如$M$和$\lambda$）。但是在许多情况，会被证明过于浪费珍贵的训练数据，因此我们需要找到更加复杂的方式。

## 1.2 概率论

模式识别的一个核心概念是不确定性。不确定性由测量时的噪音以及有限的数据集带来。概率论提供了用于量化和操作不确定性的一致性框架，并形成了模式识别的核心基础。

我们通过一个简单例子来介绍概率论的基础概念。想象我们有两个箱子，一个红色，一个蓝色。红色箱子中有2个苹果和6个橘子，而蓝色箱子中有3个苹果和一个橘子。假设我们随机选择一个箱子，并从箱子中随机选取一个水果，在检查水果的种类后返回取出的箱子中。假设我们40%情况下下选择红色箱子，60%情况下选择蓝箱子。

在这个例子中，被选择的箱子是一个随机变量，我们应该记作$B$。这个随机变量可以取两个可能值中的一个，命名为$r$（红箱子）和$b$（蓝箱子）。同样，水果的种类也是一个随机变量，可以被记作F，它也可以取两个值中的一个，$a$（苹果）或$o$（橘子）。

**我们应该定义一个事件的概率为，当总实验次数趋向于无穷时，事件发生的次数占总实验次数的比例。**

因此选择红箱子的概率为4/10，而选择蓝箱子的概率为6/10。我们用下面的方式书写概率，$p(B=r)=4/10$，$p(B=b)=6/10$。注意，在概率的定义中，**一个事件的概率一定处于$[0,1]$区间中**。并且，如果事件相互排斥，并且这些事件包含了所有实验的结果，那么这些事件的概率的加总和为1。

要解决“选择一个苹果的概率是多少？”，“已知我们取了橘子，那么我们之前选择的箱子是蓝箱子的概率是多少？”这类问题。一旦我们装备了两个概率论的初级规则——加法规则（sum rule）和乘法规则（product rule），我们就可以回答这些问题，甚至能回答模式识别中更加复杂的问题。

要推导出这些规则，我们先考虑稍微通用一些的案例。假设有两个随机变量$X$和$Y$，X取值范围为$\{x_i\}$，其中$i=1,\ldots,M$，而Y的取值范围为$\{y_j\}$，其中$j=1,\ldots,L$。我们做了共$N$次试验，将其中满足$X=x_i$和$Y=y_j$的事件次数记作$n_{ij}$。而满足$X=x_i$的事件次数记作$c_i$，而对应的满足$Y=y_j$的事件次数记作$r_j$。

![](https://raw.githubusercontent.com/taodaling/assets/master/images/2019-03-21-prml/probability-intro1.PNG)

$X$取$x_i$而$Y$取$y_j$的概率写作$p(X=x_i, Y=y_j)$，并称为$X=x_i$和$Y=y_j$的联合概率。因此
$$
p(X=x_i,Y=y_j)=\frac{n_{ij}}{N}
$$
这里我们隐式地考虑了极限$N\rightarrow \infty$。同样，$X$取值$x_i$的概率写作$p(X=x_i)$，并以分数的形式给出，因此：
$$
p(X=x_i)=\frac{c_i}{N}
$$
由于落在第i列的事件数目，实际是落在第i列上各个单元格上事件数目的综合，因此我们有$c_i=\sum_j{n_{ij}}$，而通过上面两个公式可以得到
$$
p(X=x_i)=\sum_{j=1}^L{p(X=x_i,Y=y_j)}
$$
注意$p(X=x_i)$有时也称作临界概率（marginal probability），因为它是通过加总其他随机变量得到的（这个例子中为$Y$）。

如果我们仅考虑满足$X=x_i$的事件，那么在其中满足$Y=y_j$的事件概率记作$p(Y=y_j|X=x_i)$，并称为给出$X=x_i$时$Y=y_j$的条件概率，它可以通过落在$i,j$的实验结果占落在第$i$列的实验结果的比例。
$$
p(Y=y_j|X=x_i)=\frac{n_{ij}}{c_i}
$$
进一步推到公式可以得到
$$
p(X=x_i,Y=y_j)=\frac{n_{ij}}{c_i} \cdot \frac{c_i}{N}=p(Y=y_j|X=x_i)p(X=x_i)
$$
上面就是概率的乘法规则。

之前我们很小心地区分随机变量和随机变量的取值。虽然它解决了混乱，但是也导致了注解肿块。在上下文清晰的情况下，我们直接使用$p(B)$或$p(r)$来表示某个随机变量取某个值的概率。

下面是我们总结的两条概率计算规则。

**加法规则**：
$$
p(X)=\sum_Y{p(X,Y)}
$$
**乘法规则**:
$$
p(X,Y)=p(Y|X)\cdot p(X)
$$
这里$p(X,Y)$是联结概率，读作“$X$和$Y$的概率”。而值$p(Y|X)$是一个条件概率，读作“给定$X$下$Y$的概率”。这两个简单规则组成了我们贯穿全书使用的概率机的基础。

结合乘法规则，以及对称性质$p(X,Y)=p(Y,X)$，我们可以快速得到下面的条件概率的关系。
$$
p(Y|X)=\frac{p(X|Y)p(Y)}{p(X)}
$$
上面这个公式称为贝叶斯理论，其在模式识别和机器学习中扮演了核心角色。使用加法规则，贝叶斯理论中分母可以表达为：
$$
p(X)=\sum_Y{p(X|Y)p(Y)}
$$
最后我们注意到两个变量联合概率可以分解为边缘概率的乘积，即$p(X,Y)=p(X)p(Y)$，那么就称$X$和$Y$是独立的。很显然，$X$与$Y$是独立的，等价于$p(X)=p(X|Y)$。在上面的例子中，这意味着橘子和苹果在两个桶中拥有相同的分布。

### 1.2.1 概率密度

如果当\delta x \rightarrow 0一个实数值变量x落在区间(x,x+\delta x)的概率为p(x)\delta x，那么就称p(x)为x上的概率密度。而x落在区间(a,b)上的概率为：
$$
p(x \in (a,b))=\int_a^b{p(x)dx}
$$
由于概率总是非负的，且$x$一定要处于实数坐标的某处，因此概率密度一定满足下面两个条件。
$$
p(x)\ge0
$$

$$
\int_{-\infty}^\infty{p(x)dx} = 1
$$

$x$落在区间$(-\infty,z)$的概率可以通过累计分布函数得到，其定义为：
$$
P(z)=\int_{-\infty}^z{p(x)dx}
$$
满足$P'(x)=p(x)$。如果我们有数个连续变量$x_1, \ldots , x_D$，记作向量$x$，那么我们可以定义联结概率密度$p(x)=p(x_1,\ldots ,x_D)$。而$x$落在无限小的空间$\delta x$中的概率由$p(x)\delta x$。多元概率密度必须满足
$$
p(x)\ge 0
$$

$$
\int{p(x)dx}=1
$$

如果$x$是离散变量，那么$p(x)$有时也叫做概率块函数，因为可以将定义域中的值认为是概率块。

对于概率密度的情况，概率论的加法和乘法规则，以及贝叶斯定力都可以适用。
$$
p(x)=\int{p(x,y)dy}
$$

$$
p(x,y)=p(y|x)p(x)
$$

在连续变量上，对加法和乘法原理的正式证明需要数学的一个分支——测度论，而这不在本书范围呢。



### 1.2.2 期望和协方差

涉及到概率的最重要的一个操作就是找到函数的加权平均值。一个函数$f(x)$在概率分布$p(x)$下的平均值被称为f(x)的期望，并记作E[f]。对于离散分布，它有下面形式：

$$
\mathrm{E}[f]=\sum_x{p(x)f(x)}
$$
对于连续变量的情况，期望有下面形式：
$$
\mathrm{E}[f]=\int{p(x)f(x)dx}
$$
无论哪种情况，如果我们按照概率分布给出有限的$N$个点，那么期望可以被接近于这些有限点的加总和：
$$
\mathrm{E}[f]\backsimeq \frac{1}{N} \sum_{n=1}^N{f(x_n)}
$$
上面的接近将在$N\rightarrow\infty$时将变成相等。

优势我们会考虑数个变量的期望，我们用下标来表示哪个变量被平均化，比如
$$
\mathrm{E}_x[f(x,y)]
$$
表示函数$f(x,y)$在相对$x$的分布下的平均值。注意$\mathrm{E}_x[f(x,y)]$是$y$的函数。

考虑某个条件分布下的一个条件期望，那么：
$$
\mathrm{E}_x[f|y]=\sum_x{p(x|y)f(x)}
$$
$f(x)$的方差定义为：
$$
\mathrm{var}[f]=\mathrm{E}[(f(x)-\mathrm{E}[f(x)])^2]
$$

提供了对$f(x)$在平均值$\mathrm{E}[f(x)]$的改变程度的测量。扩展上式，我们可以将公式改写为：
$$
\mathrm{var}[f]=\mathrm{E}[f(x)^2]-\mathrm{E}[f(x)]^2
$$

对于两个随机变量$x$和$y$，协方差定义为：
$$
\mathrm{cov}[x,y]=\mathrm{E}_{x,y}[\{x-\mathrm{E}[x]\}\{y-\mathrm{E}[y]\}]=\mathrm{E}_{x,y}[xy]-\mathrm{E}[x]\mathrm{E}[y]
$$
用于表示$x$和$y$一同变化的程度。如果$x$和$y$是独立的，那么他们的协方差为$0$。

对于两个随机向量$x$和$y$，那么协方差为矩阵：
$$
\mathrm{cov}[x,y]=\mathrm{E}_{x,y}[\{x-\mathrm{E}[x]\}\{y^\mathrm{T}-\mathrm{E}[y^\mathrm{T}]\}]=\mathrm{E}_{x,y}[xy^\mathrm{T}]-\mathrm{E}[x]\mathrm{E}[y^\mathrm{T}]
$$
如果我们考虑一个向量$x$和自己的协方差，我们使用一个稍微简单的标记$\mathrm{cov}[x]\equiv \mathrm{cov}[x,x]$。

### 1.2.3 贝叶斯概率


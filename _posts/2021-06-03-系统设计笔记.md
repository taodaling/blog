---
categories: techonology
layout: post
---

- Table
{:toc}

# 一般步骤

## 澄清需求边界

由于系统设计问题是开放的，没有固定的标准答案，因此必须澄清其中比较容易出现歧义的部分。我们需要在回答问题之前，确定需要设计实现哪些功能，哪些不需要实现。而这些需求会决定我们最终设计的样貌。

比如设计一个推特系统，你需要确认下面需求边界：

- 我们的用户是否由能力发布推特以及跟随他人
- 是否应该创建并展示用户的时间线
- 推特内容是否包含图片和视频
- 我们只需要关注后端还是需要同时关注前端
- 推特是否支持搜索功能
- 是否需要展示热门话题
- 是否需要向用户推送新（或重要）的推特

## 定义系统接口

确定系统需要哪些接口。比如推特系统的接口可能如下。

```java
postTweet(user_id, tweet_data, tweet_location, user_location, timestamp, …)
generateTimeline(user_id, current_time, user_location, …)
markTweetFavorite(user_id, tweet_id, timestamp, …) 
```

## 粗略估计

提前估计系统的规模是一个好主意，这会在之后我们关注扩容、分片、负载均衡和缓存的时候提供支持。

- 系统的规模是多大（新推特的数量，用户的数量）
- 我们需要多大的存储？如果推特中可以包含图片和视频，我们则需要更大的存储。
- 我们期望多大的网络带宽使用量。我们需要依据这条管理网络传输和服务器之间的负载均衡。

## 确定数据模型

提前定义数据模型，有助于澄清数据是如何在系统的不同模块之间流转的。之后它会指导我们数据分片和管理。候选人应该要有能力识别系统中的不同实体，以及它们之间的交互，以及不同层面的数据管理，比如存储，传输，加密等。下面是推特系统中的一些实体。

```
User: UserID, Name, Email, DoB, CreationData, LastLogin, etc.
Tweet: TweetID, Content, TweetLocation, NumberOfLikes, TimeStamp, etc.
UserFollowo: UserdID1, UserID2
FavoriteTweets: UserID, TweetID, TimeStamp
```

要使用哪个数据库系统？使用NoSQL还是传统的SQL数据库，应该如何存储图片和视频数据。

## 高层设计

绘制一个方形图标，其中放置5到6个盒子，表示我们系统的核心模块。我们要确定足够的模块，通过端到端解决我们实际问题。

对于推特，我们需要多个应用服务器来服务所有的读写请求，在它们前置负载均衡，来分配流量。如果我们假定读流量较多（相较于写流量），我们可以用不同的服务器来处理这样的场景。对于后端，我们需要一个高效的数据库，能够存储所有的推特数据，并且能承担巨量的读请求。我们还需要一个分布式文件存储系统来存储图片和视频。

## 细节设计

深入挖掘其中的两个到三个模块；面试官的回馈应该引导我们知道系统的哪些部分还需要深入讨论。我们应该提供多种途径，以及它们的优点和缺点，并且解释为什么我们会选择其中的一种途径。答案并不唯一，唯一重要的就是在考虑不同选项的得失的时候将系统约束牢记于心。

- 由于将会存储超大规模的数据，我们如何将数据分片为多个数据库，我们是否应该将单个用户的所有数据都存储在同一个数据库中。它会带来什么问题。
- 我们如何处理那种发很多推特或者跟随很多人的热点用户。
- 由于用户的时间线会包含最近的推特，我们是否应该组织我们的数据，以优化最近推特的扫描。
- 我们应该在哪些层次引入缓存来加速。
- 哪些组件需要更好的负载均衡。

## 识别和分解瓶颈

讨论尽可能多的瓶颈，以及用不同的途径来缓解。

- 系统是否存在单点故障问题，我们如何缓解。
- 数据是否有足够多的副本，允许我们在失去少量的服务器后我们依旧可以向用户提供服务。
- 服务是否有足够多的副本，在部分服务下线的情况时不会导致整个系统宕机。
- 我们如何监控服务的性能，在重要的组件下线或者性能下降后，是否会收到报警。

## 摘要

简单来说，提前准备和面试期间有组织地描述是系统设计环节面试成功的关键。上面提到的方法可以让你保持在正轨上，并且在系统设计的时候覆盖所有不同的层次。

# 数据库选择

## 读写

数据库一般提供的主要是读写两方面。

大部分情况下都是读多写少的场景，我们可以直接用缓存和读写分离来加速。

小部分情况下是写多读少（或相近）的场景。分情况讨论：

- 如果允许数据丢失，可以用缓冲区进行加速。
- 如果读仅要求顺序读，可以使用WAL的技术，将数据写入到日志文件尾部。
- 如果要求支持随机读写，我们可以用基于LSM算法的数据结构，比如HBase和LevelDB。这时候读性能为$O((\log_2n)^2)$，而写性能为$O(\log_2n)$，我们牺牲读性能换取写性能。

## 索引

对于整数类型的多列索引，我们可以合为一列。比如说我们要支持两类查找，一种是查找最新的数据，一种是查找某条指定的数据。那么我们可以把主键格式设计为`时间戳+递增序列号`的形式，这样我们能同时支持两类查找，且只需要建立一个索引，优化了写性能。

## 分区

分区的目的是提供水平扩展，一个分区只能分配给一个结点，而一个结点上可以配置多个分区。分区的方案有很多。

- 随机分区，但是这样二次查找的时候由于不确定数据在哪个分区上，需要遍历所有分区。
- 范围分区，优点是做范围查询的时候可以非常快的完成。但是可能会存在热点问题。
- 哈希分区，优点是分区均匀，减轻热点问题，且能很快定位数据所在的分区。但是做范围查询的时候需要遍历所有的分区。

在对多列排序的时候，我们可以在第一列上做哈希分区，后面几列上做索引。这样第一列是固定的时候，我们可以很快的在某个分片上做范围查询。

哈希分区同样无法避免热点问题，一种解决方案是对于热点数据，我们在其关键字之后再加一个随机数，这样热点数据就被再次分片到所有机器上（类似随机分区），大大降低了写的压力。但是缺点是读取热点数据的时候需要去所有分片上读取并做合并（也可以全写+任意读，这样可以减轻读压力，但是会增大写压力），我们还需要能够识别热点数据。

在分区上实现的索引有两类：

- 本地索引：每个分区维护自己的索引信息。优点是数据都落在某个分区中的时候会非常快。缺点是数据不指定关键字的时候，需要遍历所有的分区查询需要的结果，之后做合并。
- 全局索引：我们在业务上维护一个全局索引，出于性能考虑，我们需要对全局索引做范围分区。优点是我们只需要查询存在数据的分区即可，读速度加快。缺点是写数据的时候要同时更新全局索引，速度会变慢。在实践中，对全局索引的更新一般都是异步的。

## 事务

事务提供了ACID安全保证：

- A，原子性：指事务的操作要么全部成功，要么全部失败，主要用于数据库宕机重启需要丢弃那些未提交的事务以及它们所做的操作。
- C，一致性：一致性表示的是因果上的一致，比如借贷平衡。数据库提供像唯一索引、外键等功能来保证一致性，但是一致性实际上是需要应用层来保证的。
- I，隔离性：数据库需要保证每个事务执行的结果，和串行化的时候是一样的。
- D，持久性：持久性保证事务提交成功后，即使存在硬件故障或数据库崩溃，事务写入的数据都不会丢失。

隔离性的解决方案：

- 读未提交：存在脏读和脏写的问题
- 读已提交：通过行锁保证同时最多有一个事务修改解决脏写的问题，但是脏读一般不会用锁来解决，否则会影响许多只读事务的运行，脏读一般通过多版本控制来解决（具体就是对每条记录维护两个版本，一个是旧快照，一个是修改后的版本）。但是读已提交存在不可重复读的问题。
- 可重复读：大部分数据库是指快照级别隔离。
- 可串行化隔离：允许并发执行事务，但是要求结果必须与串行执行的结果相同。

一般数据库会通过多版本并发控制来避免加读锁。具体的方案就是为每个事务维护一个递增的事务ID，之后对于修改操作，会标记原记录的删除事务为当前事务，并插入一条修改后的记录，其创建事务为当前事务。在事务创建的时候同时会维护有哪些运行中（未提交）的事务池，而当前事务只能看到事务号小于自己，且不出现在未提交事务池中的那些记录。这样会导致同一条记录产生很多数据版本，需要数据库的垃圾回收进程去删除那些不再被引用的过期版本。

### 更新丢失

一般使用事务的时候，我们不会选择串行化隔离级别，而会选择其它级别。这时候会出现更新丢失的情况。比如有一个计数器，我们有两个事务要分别扣减它，如果计数器值为$0$，则业务失败。但是由于我们使用多版本控制而非加读锁的方式，因此可能两个事务都读到$1$，之后同时发生扣减，导致计数器变成了负数，使得一致性被破坏。

要解决更新丢失，一般的方案有下面几种：

- 乐观锁：通过CAS原子操作，每次替换值之前做一次比较操作。这个方案一般性能最好，但是需要数据库的支持。
- 悲观锁：在读数据的时候加上写锁（或共享锁），这样可以保证在修改数据之前，数据不会被其它事务修改。
- 自动检测：一些数据库在快照隔离级别（可重复读）可以自动检测更新丢失的情况，并终止违规的事务。但是MySQL/InnoDB不支持。

更新丢失是由同时更新同一条记录导致的。而写倾斜类似于更新丢失，它源于更新不同的记录，但是导致一致性受到破坏。比如要求值班的人至少有一人，目前有两人负责值班，并且都提交了请假的请求。这时候由于发现剩余人数为两人，因此二人的请求全部提交成功，并标志它们为请假中。但是这破坏了一致性的要求。一般写倾斜是很难自动检测的，需要通过乐观锁或悲观锁检测。

但是仅通过加锁也未必能解决所有写倾斜的场景。比如说，同时只能允许一个人请假，由于二人在查询当前请假人数的时候都是$0$，那么之后同时插入请假人信息就会破坏一致性。由于这里前提是无法查到数据，因此自然也不可能对之后插入的数据加锁。这种一个事务的写入改变另外一个事务查询结果的现象称为幻读。而快照级别隔离是无法解决幻读问题的。

幻读的解决方案有如下几种：

- 实体化冲突：我们可以额外创建一些记录，表示当前请假人数，之后对这些记录进行加锁。
- 谓词锁：谓词锁锁定的是满足条件的所有记录，包括将来插入的记录。所有写操作都需要与之前的谓语做比较。在MySQL中的间隙锁和临键锁就是谓词锁。
- 串行化：终极方案

还有一种方案是通过2PL（两阶段加锁）来解决所有的并发修改问题。具体就是读数据的时候加读锁，写数据的时候加写锁。但是这很容易产生死锁问题。

# 分布式系统

## 检测节点失效

由于分布式系统中不同节点只能通过网络进行通信，要检测一个节点失效，需要通过心跳超时机制。

但是多久超时呢，如果超时时间太久，意味着需要等待很久的时间才能宣判某个节点死亡，而较短的时间虽然能帮助我们快速发现失效节点，但是可能会错误的将一些繁忙的节点判定为失效节点。

如果网络最大传输时间为$d$，而请求处理时间为$r$，那么$2d+r$作为超时时间是个合理的选择。但是由于异步网络并不能保证最大传输时间，因此$d$可能无穷大。

更好的方式是不断对网络响应时间进行采样，从而估算出实时网络状况下$d$的值，并根据这个值判断超时。

还有一种思路是类似于电话网络拨打电话的方式，在一条线路上分配固定带宽的通信链路，该链路直到连接断开后才被释放。这样的好处是能保证数据传输的效率和延迟，我们可以通过这种方式很容易计算出超时时间。但是这种方式成本很高，真实的网络是通过抢占的方式获取带宽的，后抵达交换机的报文会参与排队，而溢出的报文会被丢弃，这样可以最大限度的利用带宽资源，节省成本。

## 时钟

每台机器都有自己的时钟硬件设备，通常是石英晶体振荡器。换言之，每台机器都维护了一个本地时间，不同机器之间的本地时间未必相同。

可以在一定程度上同步机器之间的时钟，最常用的就是网络时间协议（NTP），它根据一组专门的时间服务器来调整本地时间，而时间服务器则从更高精度的时间源获取高精度时间。

上面提到的获取时间的时钟称为墙上时钟。墙上时钟由于会通过NTP协议与时间服务器同步时间，因此可能会发生回跳的情况。

我们也不能使用第三方服务器上的时间，因为得到的时间是服务器响应我们的时候的时间，中间存在网络延迟，因此我们收到时间时已经滞后了。

一般机器还会提供一个单调时钟，它们能保证递增的性质，比如`System.nanoTime()`。单调时钟适合用来测量持续的时间段，比如超时和计时，但是它的具体值是没有意义的，因为每次机器重启后可能都会重置单调时钟。同时单调时钟的精度要比墙上时钟更高，其一般是微妙级的，而墙上时钟则是毫秒级的。

如果非要使用墙上时钟的话，一般时间API返回一个置信区间是个不错的选择。`[L,R]`表示当前时间落在该区间中，区间的大小取决于上一次NTP同步的时间。

## 分布式锁

分布式锁存在一个非常常见的问题，就是网络抖动导致锁被释放，或者持有锁的进程长时间没有被调度，再次被调度的时候锁已经过期却无法感知。我们无法在做每一次操作之前都去检查锁是否有效，因为这不仅会导致性能极度下降，同时由于CPU调度的不确定性，依旧可能存在检查完成后被调度的风险。

一种解决方案是使用fencing令牌。每次我们锁服务授予锁的时候同时返回一个fencing令牌，该令牌每授予一次就会递增。让后客户端每次向资源服务器发送请求的时候，需要带上已经持有的fencing令牌信息。由资源服务器来判别锁是否有效，如果有效才做修改操作。资源服务器可以直接对某个资源上锁的信息记录到该资源的元数据上，这样每次请求都只需要比较一下资源当前锁是否比上一次加锁的序列号大即可。

# 一致性

## 线性化

线性化是指，表现的就好像只有一个数据副本，且其上的所有操作都是原子的。

## 因果关系

保证线性化需要牺牲性能。而大部分时候我们都可以选择性能更好的因果关系来替代线性化要求。

因果关系为操作赋予了偏序关系，而线性化为操作赋予了全序关系。

如果两个操作没有因果关系，则我们可以并发执行，提高性能。CPU的指令重排就满足了因果关系。

在数据库中可以通过版本号来保持因果关系，我们可以通过将先前读到的行的版本号传回数据库，而数据库则需要检查这些行是否是最新的。因此数据库需要跟踪事务读取了哪些版本的数据。但是事务可能会读取大批的数据，但是可能仅关注其中少量记录的版本号，显式跟踪是一个不小的成本。

更好的方式是为每个操作分配一个序列号，因的序列号一定要小于果的序列号。这样我们就能确定因果关系。

- 如果是单master，那么我们可以由单master负责生成递增的序列号。这种方案存在性能。
- 如果是多master，我们可以将同一个事务的序列号全部路由到一个master上生成序列号。这个方案存在热点问题。

更好方案是使用“Lamport时间戳”。我们为每个节点维护一个计数器，并且分配一个节点id，而我们生成的序列号是一个二元组(计数器值,节点id)，以计数器值为第一关键字，节点id为第二关键字排序。这个算法的关键点在于每次去请求序列号的时候要带上我们现在获得的最大计数器值。当序列号生成服务受到请求时，如果发现请求中的计数器值大于本地的，则将当前计数器值设置请求中的计数器值。之后自增得到新的计数器值。

# 参考资料

- [Grokking the System Design Interview](https://www.educative.io/courses/grokking-the-system-design-interview)
- 《数据密集型应用系统设计》
- [如何验证线性一致性](https://catkang.github.io/2018/07/30/test-linearizability.html)
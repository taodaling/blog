---
categories: share, file
layout: post
---

- Table
{:toc}
# 前言



随着计算机的普及，人们逐渐抛弃了纸质文档的方式，而开始投入数字存储的怀抱。

数字存储的优势：

- 容量大，一枚小小的U盘就可以容纳整个图书馆中的书。
- 数据不容易损坏，而纸质文档容易因为各种原因损坏。
- 利用搜索技术可以更方便地定位文档。

好了，编不下去了，总之，就是优点多多。



但是数字存储的可靠性依赖于硬件，但是硬件的可靠性是无法保证的。硬件本身就会老化，并且还很容易受灾害影响，因此保存在硬件中的数据可以认为是易丢失的。为了避免重要数据的丢失，一般会使用多副本技术。为一份数据创建多个副本，这样任何一份副本的丢失都不会影响数据的完整性。但是多副本的方式操作起来，我们不仅仅需要自行维护硬件，还得关注硬件的状态，以及数据的同步问题，这对于个体用户是昂贵的，但是个体用户却又这样的需求，因此一些云存储也得以流行起来。



讲到了多副本，自然就存在副本之间的同步问题。考虑现在在主机A上，保存了你的一份资料，同时在主机B上，保存了这份资料的副本。现在你操作主机A，修改了原始的数据，之后自然需要将数据同步到主机B上。这时候就引入了全量更新和增量更新。

- 全量更新：全量更新是指将本地数据完整拷贝到远程主机上，并替换原始副本。

- 增量更新：增量更新是指仅将本地数据修改的部分传送到远程主机上，并将修改部分应用到原始副本上。



实现全量更新非常简单，直接通过scp远程拷贝就可以了。全量更新在数据量不大的时候是非常好的解决方案，但是当数据量达到M级之后就会体现出巨大的浪费。考虑你有一个很大的文件，比如原始而未经压缩的视频或图像，并且你需要与小组在这些媒体文件上协同工作，你们之间的数据必须不停的在彼此之间重复发送以确保大家的数据同步。或者你自己维护了一个很大的记录日常活动的Excel文件，每天都对应一个sheet页。或者你有一个巨大的应用，你需要经常将应用部署到远端服务器上以确保自己的更新生效。

每次的全量拷贝会受到网络的严格限制，可能每一次修改后你的一次同步操作就够你喝杯咖啡了。



因此全量更新在很多时候都会造成可怕的浪费，它不仅要受网络的限制还会造成高额的流量费用。增量更新才是王道！



增量更新有非常简单的实现思路。比如：

1. 在对一批文件执行批量更新时，校验每个文件在双方的哈希值，如果相同就跳过。
2. 在对单个文件执行更新时，每次编辑操作都记录操作日志，之后就发送操作日志到远端，并在远端重演所有操作。

其中1是一种通用的优化思路，这是非常有效的。但是它还是无法解决编辑单个大文件的问题。而2是一种被广泛采纳的技术，比如MySQL中主库会向从库拷贝binlog。但是2也有缺点，修改必须发生在受我们控制的环境下，这意味着我们必须能在编辑环境中加入自己记录日志的插件，但是由于IDE如此的多，我们显然无法每个都做到。



# Rsync

>  rsync is a utility for efficiently transferring and synchronizing files across networked computers by comparing the modification times and sizes of files. It is commonly found on Unix-like operating systems. The rsync algorithm is a type of delta encoding, and is used for minimizing network usage. Zlib may be used for additional data compression, and SSH or stunnel can be used for security. [[1]](#ref-1)

rsync是一个工具包，通过比较文件的修改时间和大小，从而高效地跨网络传输和同步文件。它一般能在类Unix操作系统上找到。rsync算法是一类差量编码，并被用于最小化网络消耗。可以利用Zlib进一步提供额外的数据压缩能力，而SSH或stunnel可以用来保证安全。

> Andrew Tridgell and Paul Mackerras wrote the original rsync, which was first announced on 19 June 1996. Tridgell discusses the design, implementation, and performance of rsync in chapters 3 through 5 of his Ph.D. thesis in 1999. It is currently maintained by Wayne Davison.[[1]](#ref-1)
>

最初的rsync于1996年6月19日发布，由安德鲁·垂鸠和保罗·麦克拉斯共同撰写。垂鸠在他1999年的博士论文的第3章到第5章讨论了rsync的设计、实现和性能。如今它由韦恩·戴维森维护。

> Because of the flexibility, speed, and scriptability of rsync, it has become a standard Linux utility, included in all popular Linux distributions. It has been ported to Windows (via Cygwin, Grsync, or SFU), FreeBSD, NetBSD, OpenBSD, and macOS.[[1]](#ref-1)

rsync的灵活性，速度以及适配能力，已经使它成为了标准Linux工具包，包含在所有流行的Linux发行版本中。它也已经迁移到了Windows（通过Cygwin，Grsync或者SFU），FreeBSD，NetBSD，OpenBSD和macOS上。

## 小插曲

作为rsync的作者，安德鲁·垂鸠还间接造成git的出现。

> 自2002年开始，林纳斯·托瓦兹决定使用BitKeeper作为Linux内核主要的版本控制系统用以维护代码。因为BitKeeper为专有软件，这个决定在社群中长期遭受质疑。在Linux社群中，特别是理查德·斯托曼与自由软件基金会的成员，主张应该使用开放源代码的软件来作为Linux内核的版本控制系统。林纳斯·托瓦兹曾考虑过采用现成软件作为版本控制系统（例如Monotone），但这些软件都存在一些问题，特别是性能不佳。现成的方案，如CVS的架构，受到林纳斯·托瓦兹的批评。
>
> 2005年，安德鲁·垂鸠写了一个简单程序，可以连接BitKeeper的存储库，BitKeeper著作权拥有者拉里·麦沃伊认为安德鲁·垂鸠对BitKeeper内部使用的协议进行逆向工程，决定收回无偿使用BitKeeper的许可。Linux内核开发团队与BitMover公司进行磋商，但无法解决他们之间的歧见。林纳斯·托瓦兹决定自行开发版本控制系统替代BitKeeper，以十天的时间编写出git第一个版本。[[2]](#ref-2)

## rsync原理

rsync原理非常简单。下面的图展示了rsync的整体流程。

![A To B](https://raw.githubusercontent.com/taodaling/assets/master/images/2019-03-12-differ/rsync-process.png)

下面我们了解每个步骤具体做了什么。

第一步，A主机将文件名称和相对路径发送给B主机。

第二步，B主机将文件切分成若干个固定大小的块，除了最后一块外每一块的大小都相同。之后B主机为每一个块计算两个摘要值，一个弱摘要，一个强摘要。弱摘要采用滚动哈希算法，原版中采用的adler-32算法，而强摘要可以选择SHA-1，MD5等，原版中采用的是MD4算法。

比如我们按照1024作为固定大小，那么第0块的范围是[0, 1024)，第1块的范围是\[1024, 2048)，第k块的范围是[1024 \* k, 1024 \* (k + 1))

第三步，B主机将每一个分块的强弱摘要返回给A主机，你可以认为数据类似于：

```json
[
    {
        "blockId": 1,
        "weakChecksum": 9863,
        "strongChecksum": "AC765D7F65310EA5..."
    },
...
]
```

第四步，A主机同样对本地文件分块，并采用与B主机分块一样的大小。但是分块策略并不完全相同。

假设我们按照1024作为固定大小，A主机下第0块的范围是[0, 1024)，第1块的范围是[1, 1025)，第k块范围是[k, 1024 + k)。

之后计算差量的方式非常有趣。由于之前已经从B主机接收到分块的摘要信息，A主机将这些摘要信息维护到哈希表中，弱摘要用于确定slot的下标，强摘要作为关键字，块ID作为值。比如

```json
{
    9863 => "AC765D7F65310EA5...":1,...
    ...
}
```

之后按序遍历A主机下的分块。由于采用的是滚动哈希，因此当我们计算出第i块的弱哈希时，可以以O(1)的时间复杂度内计算出第i+1块的弱哈希值。下面说明整体计算流程：

![calc differ](https://raw.githubusercontent.com/taodaling/assets/master/images/2019-03-12-differ/rsync-calc-differ.png)

第五步中，A主机将第四步输出的操作序列发送到B主机。

第六步中，B主机执行操作序列，add命令代表向新文件尾部追加一个字节，copy命令表示拷贝原文件的一个块内容到新文件尾部。

## 演示

假设我们B中文件内容为`你好啊，铁开诚`，而A中的文件为`你好吗，铁开诚？`，并假设块大小为2。

第4步流程如下：

输入"你好吗"，没有匹配，发送命令"add 你"。

输入"好吗，"，没有匹配，发送命令"add 好"。

输入"吗，铁"，没有匹配，发送命令"add 吗"。

输入"，铁开"，发现匹配，发送命令"copy 3"。

输入"诚？"，由于长度不足，直接发送"add 诚", "add？"。

之后在B端执行这些命令。首先它创建一个临时文件temp，之后在临时文件上执行操作序列。第6步流程如下，

"add 你"，执行完后文件内容为"你"

"add 好"，执行完后文件内容为"你好"

"add 吗"，执行完后文件内容为"你好吗"

"copy 3"，执行完后文件内容为"你好啊，铁开"

"add 诚", "add？"，执行完后文件内容为"你好啊，铁开诚?"

## 分析

采用了rsync算法后，文件大小对于真正每次的传输数据量来说影响不大，其仅于你的修改次数和块大小有关。因此不管文件有多大，增量算法都可以非常好的运行。当然由于使用了rsync，差量的计算和应用将会带来比较多的CPU消耗。

# Myers



# 参考文献

<a name="ref-1"></a> \[1\] https://en.wikipedia.org/wiki/Rsync

<a name="ref-2"></a> [2] https://zh.wikipedia.org/wiki/Git

<a name="ref-3"></a> [3] https://www.andrew.cmu.edu/course/15-749/READINGS/required/cas/tridgell96.pdf
---
categories: programming
layout: post
---

{:toc}

# 基础知识

Kafka的数据单元称为消息，消息由字节数组组成。消息可以有一个可选的元数据，也就是键，键也是一个字节数组，键用来决定消息最后存储在主题的哪个分区中。

消息按照主题进行分类，一个主题可以细分为若干个分区，一个分区就是一个提交日志，消息以追加的方式写入到分区尾部，然后以先入先出的方式被读取。分区分布在不同的机器上，从而提供比单机更强的性能。

由于一个主题有多个分区，因此不能保证整个主题消息的顺序，但是可以保证单个分区中消息的顺序。

消费者是消费者群组的一部分。主题的分区会被分配给群组中的某个消费者，同一个分区仅被一个消费者所使用。如果群组中的某个消费者下线，它负责的分区会被重新分配给群组中的其它消费者。一个主题可以同时被多个消费者群组消费。

一个独立的kafka服务器被称为broker。broker提供读写能力，单个broker可以轻松处理数千个分区以及每秒百万级的消息量。

一个集群是由多个broker组成。其中一个broker作为控制器，负责管理工作，包括分配分区、监控broker。

一个分区会被分配以副本的形式分配到多台broker上，其中仅一个副本作为分区的master，所有写操作都会经由master分发给其它的副本。如果master失效，则会由其它副本接管。

一个主题下的分区数可以增加，但是不允许减少。并且如果分区数增加，是不会做数据迁移，因此老数据保留在老分区中，而新的数据会被重新散列到不同的分区中，这时候不能保证相同键的消息都处于同一个分区中。

# 生产者

![https://raw.githubusercontent.com/taodaling/taodaling.github.io/master/assets/images/2021-07-01-kafka/produce_message.PNG](https://raw.githubusercontent.com/taodaling/taodaling.github.io/master/assets/images/2021-07-01-kafka/produce_message.PNG)

`ProducerRecord`对应一个消息，其中包含主题和发送的内容。我们还可以额外指定键和分区。

序列化器负责把其中的键和值对象进行序列化，方便在网络中传输。

接下来，分区器负责为消息选择分区。如果`ProducerRecord`中我们指定了分区，则按照这个分区投递，否则按照其中的键进行分区。

之后记录被添加到一个记录批次中，批次中的所有消息都会被发送到相同的主题和分区上。有一个独立的线程负责将这些记录发送到相应的broker上。

服务器在收到消息后会返回一个响应，如果是成功写入，则返回一个`RecordMetaData`对象，它包含主题和分区信息，以及记录在分区中的偏移量。如果发送失败，则会收到一个错误。根据错误类型可以分为两类，第一类是临时性错误，比如说连接错误，无主错误，这时候生产者在收到错误之后会尝试重新发送消息，如果几次重试都是失败，就返回错误信息。还有一类错误是非临时性错误，比如消息体太大了，对于这种错误，kafka不会进行重试。

## 生产者配置

- `bootstrap.servers`:指定broker地址，不需要指定全部的broker，生产者会自动从连接的broker得到集群中所有broker的信息。
- `key.serializer`:键的序列化器类型
- `value.serializer`:值的序列化器类型
- `acks`:指定必须由多少个分区副本收到消息，生产者才会认为消息写入是成功的。其有如下选项。
  - `0`:生产者发送消息后不等待服务器响应
  - `1`:分区的master节点必须收到消息
  - `all`:所有分区副本所在节点收到消息
- `buffer.memory`:生产者内存缓存区大小，用于存储批次数据。如果应用程序发送消息的速度超过发送到服务器的速度，会导致缓存区空间不足。接下来的`send`方法调用会阻塞等待。
- `compression.type`:指定压缩算法。
  - `snappy`:不错的压缩比，以及很高的性能
  - `gzip`:更高的压缩比，性能较差
  - `lz4`
- `retries`:对于临时性错误，最大重发次数。
- `batch.size`:一个批次的大小。并非只有满批次才会被发送，一个只有一条消息的批次也有可能会被发送。
- `linger.ms`:一个批次在创建后的超时时间，一个批次会在达到超时时间或占满了的情况下被发送。
- `client.id`:消息来源。
- `max.in.flight.requests.per.connection`:生产者在收到服务器响应之前可以发送多少个消息。（同时发送的消息不一定能保证顺序，因此如果强制要求有序，必须将这个值设为1，但是会严重影响性能）
- `timeout.ms`:broker 等待同步副本返回消息确认的时间
- `request.timeout.ms`:了生产者在发送数据时等待服务器返回响应的时间
- `metadata.fetch.timeout.ms`:生产者在获取元数据（比如目标分区的首领是谁）时等待服务器返回响应的时间
- `max.block.ms`:当生产者的发送缓冲区已满，或者没有可用的元数据时，这些方法就会阻塞。在阻塞时间达到`max.block.ms`时，生产者会抛出超时异常。
- `max.request.size`:单个请求里所有消息总的大小，同时也是能发送的单个消息的最大值。
- `receive.buffer.bytes`和`send.buffer.bytes`:TCP socket 接收和发送数据包的缓冲区大小，-1表示使用操作系统的默认值。


# 消费者

Kafka中一个消费群组订阅同一批主题，主题下的分区会分配给群组中的消费者，每个分区都正好分配给一个消费者，一个消费者可能分配到多个分区（如果消费者数目多于分区数，则会有部分消费者闲置）。同一个主题下可以同时有多个消费者群组。

一个消费者群组可以通过正则表达式同时订阅多个主题，如果有新的主题被创建，会与正则表达式比较，如果匹配则也会被这个群组所订阅。

在消费者加入退出，或者主题加入新的分区的情况下，会发生分区重分配，这个过程称为再平衡。

消费者需要向群组协调器的broker（不同的群组可能有不同的协调器）发送心跳来维持它们和群组的从属关系，以及它们对分区的所有权。如果协调器长时间没有收到某个消费者发送的心跳，那么会认为这个消费者已经下线。

当消费者加入群组的时候，它会向群组协调器发送一个JoinGroup请求。第一个加入群组的消费者成为群主。群主从协调器那里获得群组中的活跃成员列表，并负责为每一个消费者分配分区。它使用一个实现了`PartitionAssigner`接口的类来决定哪些分区属于哪些消费者。分配完成后，群主把分配列表发送给群组协调器，协调器再把分配信息分发给群组中的所有消费者。每个消费者只能看到自己的分配信息。这个过程在每次再平衡的时候发生。

## 消费者配置

- `fetch.min.bytes`:该属性指定了消费者从服务器获取记录的最小字节数。
- `fetch.max.wait.ms`:指定broker在记录不足时的等待时间，默认是 500ms。
- `max.partition.fetch.bytes`:服务器从每个分区里返回给消费者的最大字节数。它的默认值是 1MB。`max.partition.fetch.bytes`的值必须比broker能够接收的最大消息的字节数（通过`max.message.size`属性配置）大，否则消费者可能无法读取这些消息。
- `session.timeout.ms`:消费者在被认为死亡之前可以与服务器断开连接的时间，默认是 3s。
- `heartbeat.interval.ms`:心跳的频率。
- `auto.offset.reset`:消费者在读取一个没有偏移量的分区或者偏移量无效的情况下（因消费者长时间失效，包含偏移量的记录已经过时并被删除）该作何处理。默认值是 latest，意思是说，在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）。另一个值是 earliest，意思是说，在偏移量无效的情况下，消费者将从起始位置读取分区的记录。
- `enable.auto.commit`:消费者是否自动提交偏移量，默认值是true。为了尽量避免出现重复数据和数据丢失，可以把它设为 false，由自己控制何时提交偏移量。如果把它设为 true，还可以通过配置`auto.commit.interval.ms`属性来控制提交的频率。
- `partition.assignment.strategy`:分配策略。
  - `Range`:该策略会把主题的若干个连续的分区分配给消费者。默认策略。
  - `RoundRobin`:把主题的所有分区通过轮询的方式分配给消费者（持有最多分区的消费者分区数比最少分区最多多1）。
- `client.id`:客户端标识符
- `max.poll.records`:单次调用 call() 方法能够返回的记录数量。
- `receive.buffer.bytes`和`send.buffer.bytes`:socket 在读写数据时用到的 TCP 缓冲区也可以设置大小。如果它们被设为 -1，就使用操作系统的默认值。

## 偏移量

消费者通过分区偏移量区分分区中哪些消息已经被消费，哪些消息未被消费。在发生再平衡的时候一些消费者掌管之前不属于它的分区，这时候就可以通过偏移量从上一条未被消费的消息开始读取。

消费者需要负责提交偏移量。其实现原理是消费者向一个叫做`_consumer_offset`的特殊主题发送消息，消息里面包含每个分区的偏移量。

如果在消息处理完后才提交偏移量，那么可能会导致消息被重复消费。而如果在消息处理前提交偏移量，那么可能会导致消息丢失。

如果启用了自动提交偏移量（`enable.auto.commit`），那么每经过`auto.commit.interval.ms`时间，消费者会把`poll`方法接收到的最大偏移量提交上去。

一般我们都是接受消息被重复消费，而不接受消息丢失。因此会选择较大的`auto.commit.interval.ms`或者手动通过`commitSync`或`commitAsync`方法提交偏移量，前者是同步版本，后者是异步的（如果使用重试的话，可能会出现较大偏移量先被提交，而较小偏移量后被提交，导致重复消费）。一般较好的方法是使用`commitAsync`提交偏移量但是不重试，在消费者关闭之前使用`commitSync`同步提交最终的偏移量并不断重试直到成功。

你也可以手动设置分区的偏移量，比如你手动将偏移量保存在了数据库（这样就能保证消息的偏移量和数据库事务同时被提交），那么可以使用`seek`方法手动设置偏移量。

## 再均衡监听

消费者在关闭和再平衡之前，需要做一些清理操作。比如关闭必要的文件、连接，清理缓冲区，提交最新的偏移量等。

我们可以在通过`subscribe`订阅主题的时候，提供一个`ConsumerRebalanceListener`实例监听再均衡事件。

## 优雅关闭

要优雅关闭消费者，我们可以通过另外一个线程（比如JVM的关闭钩子线程）调用`consumer.wakeup()`方法，它会打断当前进行中的`poll`并抛出异常或在下一次`poll`发生的时候抛出`WakeupException`。

主循环应该负责提交偏移量，并调用`consumer.close()`通知群组协调器自己要离开群组。

# 参考资料

- 《Kafka权威指南》
